{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e3969e4-ceb5-4610-aa36-a5c8c8dcb971",
   "metadata": {},
   "source": [
    "# Challenge submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4a2e03-2aa6-44ea-bfb2-a8ada4f9c8c3",
   "metadata": {},
   "source": [
    "## Goal 1:\n",
    "Create 4 lazy iterators, one for each of the 4 files that:\n",
    "> returns named tuples <br>\n",
    "> data types are appropriate for each field <br>\n",
    "> the 4 iterators are independent of each other <br>\n",
    "\n",
    "Hints:\n",
    "> Use CSV module, specificaly `csv.reader` to parse correctly the data, and deal with the quotes issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72b2633b-a213-4f9d-b8c3-ffbf0c859886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "fname_employment = 'project_4_description/employment.csv'\n",
    "fname_personal_info = 'project_4_description/personal_info.csv'\n",
    "fname_status = 'project_4_description/update_status.csv'\n",
    "fname_vehicles = 'project_4_description/vehicles.csv'\n",
    "fnames = fname_employment, fname_personal_info, fname_status, fname_vehicles\n",
    "\n",
    "# Parsers\n",
    "personal_parser = (parse_str,parse_str,parse_str,parse_str,parse_str)\n",
    "employment_parser = (parse_str,parse_str,parse_str,parse_str)\n",
    "vehicle_parser = (parse_str,parse_str,parse_str,parse_int)\n",
    "update_status_parser = (parse_str,parse_date, parse_date)\n",
    "parsers = employment_parser, personal_parser, update_status_parser, vehicle_parser\n",
    "\n",
    "# Named Tuple Names\n",
    "personal_class_name = 'Personal'\n",
    "employment_class_name = 'Employment'\n",
    "vehicle_class_name = 'Vehicle'\n",
    "update_status_class_name = 'UpdateStatus'\n",
    "class_names = employment_class_name, personal_class_name, update_status_class_name, vehicle_class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f05a855-885c-4804-8894-27b3e2cd072f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Course solution\n",
    "\n",
    "import csv\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "# Parses the data from file to a list per row\n",
    "def csv_parser(fname, *, delimiter=',', quotechar='\"', include_header=False):\n",
    "    with open(fname) as f:\n",
    "        reader = csv.reader(f, delimiter=delimiter, quotechar=quotechar)\n",
    "        if not include_header:\n",
    "            next(f)\n",
    "        yield from reader\n",
    "\n",
    "# parses strings\n",
    "def parse_str(s,*,default=None):\n",
    "    try:\n",
    "        return str(s)\n",
    "    except ValueError:\n",
    "        return default\n",
    "    \n",
    "# parses int\n",
    "def parse_int(n,*,default=None):\n",
    "    try:\n",
    "        return int(n)\n",
    "    except ValueError:\n",
    "        return default\n",
    "    \n",
    "# parses dates with default format\n",
    "def parse_date(value,*,fmt='%Y-%m-%dT%H:%M:%SZ',default=None):\n",
    "    try:\n",
    "        return datetime.strptime(value,fmt)\n",
    "    except ValueError:\n",
    "        return default\n",
    "\n",
    "\n",
    "# extracts file header\n",
    "def extract_field_names(fname):\n",
    "    reader = csv_parser(fname, include_header=True)\n",
    "    return next(reader)\n",
    "\n",
    "\n",
    "# Creates an empty namedtuple from file\n",
    "def create_named_tuple_class(fname, class_name):\n",
    "    fields = extract_field_names(fname)\n",
    "    return namedtuple(class_name, fields)\n",
    "\n",
    "\n",
    "# Takes in a filename, class_name and a dtype parser and returns a namedtuple\n",
    "def iter_file(fname, class_name, parser):\n",
    "    nt_class = create_named_tuple_class(fname, class_name)\n",
    "    reader = csv_parser(fname)\n",
    "    \n",
    "    for row in reader:\n",
    "        parsed_data = (parse_fn(value) for value, parse_fn in zip(row, parser))\n",
    "        yield nt_class(*parsed_data)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d59f7f26-0dfc-4f68-8ad4-6853055869e0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employment(employer='Stiedemann-Bailey', department='Research and Development', employee_id='29-0890771', ssn='100-53-9824')\n",
      "Employment(employer='Nicolas and Sons', department='Sales', employee_id='41-6841359', ssn='101-71-4702')\n",
      "Employment(employer='Connelly Group', department='Research and Development', employee_id='98-7952860', ssn='101-84-0356')\n",
      "\n",
      "\n",
      "\n",
      "Personal(ssn='100-53-9824', first_name='Sebastiano', last_name='Tester', gender='Male', language='Icelandic')\n",
      "Personal(ssn='101-71-4702', first_name='Cayla', last_name='MacDonagh', gender='Female', language='Lao')\n",
      "Personal(ssn='101-84-0356', first_name='Nomi', last_name='Lipprose', gender='Female', language='Yiddish')\n",
      "\n",
      "\n",
      "\n",
      "UpdateStatus(ssn='100-53-9824', last_updated=datetime.datetime(2017, 10, 7, 0, 14, 42), created=datetime.datetime(2016, 1, 24, 21, 19, 30))\n",
      "UpdateStatus(ssn='101-71-4702', last_updated=datetime.datetime(2017, 1, 23, 11, 23, 17), created=datetime.datetime(2016, 1, 27, 4, 32, 57))\n",
      "UpdateStatus(ssn='101-84-0356', last_updated=datetime.datetime(2017, 10, 4, 11, 21, 30), created=datetime.datetime(2016, 9, 21, 23, 4, 7))\n",
      "\n",
      "\n",
      "\n",
      "Vehicle(ssn='100-53-9824', vehicle_make='Oldsmobile', vehicle_model='Bravada', model_year=1993)\n",
      "Vehicle(ssn='101-71-4702', vehicle_make='Ford', vehicle_model='Mustang', model_year=1997)\n",
      "Vehicle(ssn='101-84-0356', vehicle_make='GMC', vehicle_model='Yukon', model_year=2005)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for fname, class_name, parser in zip(fnames, class_names, parsers):\n",
    "        file_iter = iter_file(fname, class_name, parser)\n",
    "        \n",
    "        for _ in range(3):\n",
    "            print(next(file_iter))\n",
    "            \n",
    "        print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce8583f-c598-4d71-b418-3a739b345cb9",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b965977-c2d9-497e-8b33-4209f1e7142a",
   "metadata": {},
   "source": [
    "## Goal 2\n",
    "Create a single iterable that combines all the data from all four files.\n",
    "> The output will be 1 row per ssn containing data from all 4 previous iterators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08c111b-1471-40d7-acd9-7c6709e0bef0",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54cffa87-fa54-4211-9fa7-ccecd37b7e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "# Field Inclusion/Exclusion\n",
    "personal_fields_compress = [True, True, True, True, True]\n",
    "employment_fields_compress = [True, True, True, False]\n",
    "vehicle_fields_compress = [False, True, True, True]\n",
    "update_status_fields_compress = [False, True, True]\n",
    "compress_fields = (employment_fields_compress, personal_fields_compress, \n",
    "                   update_status_fields_compress, vehicle_fields_compress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2914355f-d661-4256-ae7e-5f6aa182af9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combo_named_tuple_class(fnames, compress_fields):\n",
    "    compress_fields = itertools.chain.from_iterable(compress_fields)\n",
    "    field_names =  itertools.chain.from_iterable(extract_field_names(fname) for fname in fnames)\n",
    "    compressed_field_names = itertools.compress(field_names, compress_fields)\n",
    "    return namedtuple('Data', compressed_field_names)\n",
    "\n",
    "\n",
    "def iter_combined(fnames, class_names, parsers, compress_fields):\n",
    "    combo_nt = create_combo_named_tuple_class(fnames, compress_fields)\n",
    "    # Zip all 4 iterators\n",
    "    zipped_tuples = zip(*[iter_file(fname, class_name, parser)\n",
    "               for fname, class_name, parser in zip(fnames, class_names, parsers)])\n",
    "    \n",
    "    # Merge multiple namedtuple rows into a single row\n",
    "    merged_iter = (itertools.chain.from_iterable(zipped_tuple) for zipped_tuple in zipped_tuples)\n",
    "    # Chain compress_fields lists into a single list. We transform it into a tuple so it does not\n",
    "    # get exhausted\n",
    "    compress_fields = tuple(itertools.chain.from_iterable(compress_fields))\n",
    "    # Remove the unwanted ssn that are common in all 4 iterators\n",
    "    for row in merged_iter:\n",
    "        compressed_row = itertools.compress(row, compress_fields)\n",
    "        yield combo_nt(*compressed_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27f7bfc2-2de5-4d4c-b720-8bd2438cea66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(employer='Stiedemann-Bailey', department='Research and Development', employee_id='29-0890771', ssn='100-53-9824', first_name='Sebastiano', last_name='Tester', gender='Male', language='Icelandic', last_updated=datetime.datetime(2017, 10, 7, 0, 14, 42), created=datetime.datetime(2016, 1, 24, 21, 19, 30), vehicle_make='Oldsmobile', vehicle_model='Bravada', model_year=1993)\n",
      "Data(employer='Nicolas and Sons', department='Sales', employee_id='41-6841359', ssn='101-71-4702', first_name='Cayla', last_name='MacDonagh', gender='Female', language='Lao', last_updated=datetime.datetime(2017, 1, 23, 11, 23, 17), created=datetime.datetime(2016, 1, 27, 4, 32, 57), vehicle_make='Ford', vehicle_model='Mustang', model_year=1997)\n",
      "Data(employer='Connelly Group', department='Research and Development', employee_id='98-7952860', ssn='101-84-0356', first_name='Nomi', last_name='Lipprose', gender='Female', language='Yiddish', last_updated=datetime.datetime(2017, 10, 4, 11, 21, 30), created=datetime.datetime(2016, 9, 21, 23, 4, 7), vehicle_make='GMC', vehicle_model='Yukon', model_year=2005)\n",
      "Data(employer='Upton LLC', department='Marketing', employee_id='56-9817552', ssn='104-22-0928', first_name='Justinian', last_name='Kunzelmann', gender='Male', language='Dhivehi', last_updated=datetime.datetime(2017, 3, 28, 12, 38, 29), created=datetime.datetime(2016, 4, 15, 11, 37, 17), vehicle_make='Oldsmobile', vehicle_model='Intrigue', model_year=2000)\n",
      "Data(employer='Zemlak-Olson', department='Business Development', employee_id='46-2886707', ssn='104-84-7144', first_name='Claudianus', last_name='Brixey', gender='Male', language='Afrikaans', last_updated=datetime.datetime(2018, 2, 19, 1, 34, 33), created=datetime.datetime(2016, 3, 15, 14, 7, 57), vehicle_make='Ford', vehicle_model='Crown Victoria', model_year=2008)\n"
     ]
    }
   ],
   "source": [
    "result = iter_combined(fnames, class_names, parsers, compress_fields)\n",
    "\n",
    "for i in itertools.islice(result,5):\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
